{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import re\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer #for tokenize text \n",
    "from nltk.stem.snowball import SnowballStemmer # for Stemming word \n",
    "#from nltk.stem.lancaster import LancasterStemmer \n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split #for splitting data into train and test\n",
    "from sklearn.feature_extraction.text import CountVectorizer #for vectorize text into sparse matrix \n",
    "from sklearn import metrics # for findin the accuracy of model \n",
    "import collections #for finding each class true prediction frequency \n",
    "from sklearn.naive_bayes import MultinomialNB # import and instantiate MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0                @VirginAmerica What @dhepburn said.   neutral\n",
      "1  @VirginAmerica plus you've added commercials t...  positive\n",
      "2  @VirginAmerica I didn't today... Must mean I n...   neutral\n",
      "3  @VirginAmerica it's really aggressive to blast...  negative\n",
      "4  @VirginAmerica and it's a really big bad thing...  negative\n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tweet = pd.read_csv(\"Tweets.csv\") #reading tweet.csv file using pandas\n",
    "df=tweet.iloc[:,(10,1)]  \n",
    "df.columns = ['text', 'sentiment'] #only two column from data text and sentiment \n",
    "data= df\n",
    "print data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0                                       [What, said]   neutral\n",
      "1  [plus, youve, added, commercials, to, the, exp...  positive\n",
      "2  [I, didnt, today, Must, mean, I, need, to, tak...   neutral\n",
      "3  [its, really, aggressive, to, blast, obnoxious...  negative\n",
      "4  [and, its, a, really, big, bad, thing, about, it]  negative\n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# removes every thing except text \n",
    "data['text']=data['text'].str.replace(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([0-9])\",\"\")\n",
    "# now tokenize text\n",
    "data['text']=data['text'].apply(nltk.word_tokenize)\n",
    "print data.head() #first five row is printing after tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0                                       [what, said]   neutral\n",
      "1  [plus, youv, ad, commerci, to, the, experi, ta...  positive\n",
      "2  [i, didnt, today, must, mean, i, need, to, tak...   neutral\n",
      "3  [it, realli, aggress, to, blast, obnoxi, enter...  negative\n",
      "4   [and, it, a, realli, big, bad, thing, about, it]  negative\n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Stemming each word \n",
    "stemmer = SnowballStemmer('english')\n",
    "data['text']=data['text'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0                                             [said]   neutral\n",
      "1          [plus, youv, ad, commerci, experi, tacki]  positive\n",
      "2  [didnt, today, must, mean, need, take, anoth, ...   neutral\n",
      "3  [realli, aggress, blast, obnoxi, entertain, gu...  negative\n",
      "4                          [realli, big, bad, thing]  negative\n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# removing stopword \n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "data['text']=data['text'].apply(lambda x: [y for y in x if y not in stopwords])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0                                               said   neutral\n",
      "1                 plus youv ad commerci experi tacki  positive\n",
      "2         didnt today must mean need take anoth trip   neutral\n",
      "3  realli aggress blast obnoxi entertain guest fa...  negative\n",
      "4                               realli big bad thing  negative\n",
      "\n",
      "[5 rows x 2 columns]\n",
      "data shape =  (14640, 2)\n"
     ]
    }
   ],
   "source": [
    "# Detokenize cleaned dataframe for vectorizing\n",
    "data['text'] = data['text'].str.join(\" \")\n",
    "print data.head()\n",
    "print \"data shape = \", data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0                                               said          1\n",
      "1                 plus youv ad commerci experi tacki          2\n",
      "2         didnt today must mean need take anoth trip          1\n",
      "3  realli aggress blast obnoxi entertain guest fa...          0\n",
      "4                               realli big bad thing          0\n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#transforming postive to 2, netural to 1, negative to 0\n",
    "sentiment = sorted(data['sentiment'].unique())\n",
    "sentiment_mapping = dict(zip(sentiment, range(0, len(sentiment) + 1)))\n",
    "data['sentiment']  = data['sentiment'].map(sentiment_mapping).astype(int)\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data =  (10980,) size of test data =  (3660,)\n",
      "size of target train data =  (10980,) size of target test data =  (3660,)\n"
     ]
    }
   ],
   "source": [
    "#splitting data into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print \"size of train data = \", X_train.shape,\"size of test data = \", X_test.shape\n",
    "print \"size of target train data = \", y_train.shape, \"size of target test data = \",y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizing size of x_train =  (10980, 8360)\n",
      "After vectorizing size of x_test =  (3660, 8360)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "#  fit and transform X_train into X_tr\n",
    "X_tr =  vect.fit_transform(X_train)\n",
    "# transform X_test into X_te\n",
    "X_te = vect.transform(X_test)\n",
    "print \"After vectorizing size of x_train = \", X_tr.shape\n",
    "print \"After vectorizing size of x_test = \", X_te.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769672131148\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "# train the model using X_train_dtm\n",
    "nb.fit(X_tr, y_train)\n",
    "# make class predictions for X_te\n",
    "y_pred = nb.predict(X_te)\n",
    "# calculate accuracy of class predictions\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2184,   77,   30],\n",
       "       [ 425,  295,   54],\n",
       "       [ 208,   49,  338]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postive = 2, netural = 1, negative = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Precision: When a given class is predicted, how often are those predictions correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77529286475\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the precision for class 0\n",
    "precision0 = 2184 / float(2184 + 425 + 208 )\n",
    "print(precision0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.700712589074\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the precision for class 1\n",
    "precision1 = 295 / float(77 + 295 + 49 )\n",
    "print(precision1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800947867299\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the precision for class 2\n",
    "precision2 = 338 / float(30 + 54 + 338 )\n",
    "print(precision2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recall: \"When a given class is the true class, how often is that class predicted?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953295504147\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the recall for class 0\n",
    "recall0 = 2184 / float(2184 + 77 + 30 )\n",
    "print(recall0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.381136950904\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the recall for class 1\n",
    "recall1 = 295 / float(425 + 295 + 54 )\n",
    "print(recall1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568067226891\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the recall for class 2\n",
    "recall2 = 338 / float(208 + 49 + 338 )\n",
    "print(recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1 score:  is a weighted average of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855129209084\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the F1 score for class 0\n",
    "f1 = 2 * (precision0 * recall0) / (precision0 + recall0)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493723849372\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the F1 score for class 1\n",
    "f1 = 2 * (precision1 * recall1) / (precision1 + recall1)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664700098328\n"
     ]
    }
   ],
   "source": [
    "# manually calculate the F1 score for class 2\n",
    "f1 = 2 * (precision2 * recall2) / (precision2 + recall2)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Support: \"How many observations exist for which a given class is the true class?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2291, 1: 774, 2: 595})\n"
     ]
    }
   ],
   "source": [
    "support = collections.Counter(y_test)\n",
    "print (support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86      2291\n",
      "          1       0.70      0.38      0.49       774\n",
      "          2       0.80      0.57      0.66       595\n",
      "\n",
      "avg / total       0.76      0.77      0.75      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print obove result using classification report \n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
